{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOuDhiIg0hjEudC2GLPUtDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguel-kjh/Analysis-of-tweets/blob/main/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI461HkwrCLu",
        "outputId": "6ad0d3c8-fb46-4b76-82c3-a10028130940"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import string\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "np.random.seed(777)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LbyohCIraV8",
        "outputId": "b57eea42-b94b-4d40-dcdd-a0119b4b2702"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edR5knTVrUra",
        "outputId": "6ee77f45-aa36-48dc-b930-6935f700d475"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/SIANI Master/CI/Práctica/spanish-arilines-tweets-sentiment-analysis'\n",
        "!ls '/content/drive/My Drive/SIANI Master/CI/Práctica/spanish-arilines-tweets-sentiment-analysis'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline.ipynb\t      test_data_un.csv\t tweets_public.csv\tval_data_ba.csv\n",
            "sampleSubmission.csv  train_data_ba.csv  tweets_public.xlsx\tval_data_un.csv\n",
            "test_data_ba.csv      train_data_un.csv  tweets_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTUmGnY4zzSS"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "As a baseline a classical approach is tested using a bag of words with a TFidf approach. The models that have been used are: \n",
        "\n",
        "- Random Forest\n",
        "- GaussianNB\n",
        "- XGBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHPUZ-Or4JZ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "class Classifier:\n",
        "  def __init__(self, clf, name: str):\n",
        "    self.classifier = clf\n",
        "    self.name       = name\n",
        "\n",
        "  def train(self, Xtrain, Ytrain, Xtest, Ytest):\n",
        "    self.classifier.fit(Xtrain, Ytrain)\n",
        "\n",
        "    self.predict = self.classifier.predict(Xtest)\n",
        "    self.Ytest   = Ytest\n",
        "    self.acc     = round(accuracy_score(Ytest, self.predict)*100, 4)\n",
        "\n",
        "  def __lt__(self, other):\n",
        "      if not isinstance(other, type(self)): return NotImplemented\n",
        "      return self.acc < other.acc\n",
        "\n",
        "  def __eq__(self, other):\n",
        "      if not isinstance(other, type(self)): return NotImplemented\n",
        "      return self.acc == other.acc\n",
        "\n",
        "  def __str__(self):\n",
        "    try:\n",
        "      return \"%s:\\nAccurracy: %s\\nRecall and Precision:\\n%s\" %(self.name, self.acc, classification_report(self.Ytest, self.predict))\n",
        "    except AttributeError:\n",
        "      raise RuntimeError(\"Model not trained\")\n",
        "\n",
        "class ClassifierCollection:\n",
        "  def __init__(self, collection: List[Classifier] = []) -> None:\n",
        "      self._collection = collection\n",
        "  \n",
        "  def add_classifier(self, classifier: Classifier):\n",
        "      self._collection.append(classifier)\n",
        "  \n",
        "  def train(self, Xtrain, Ytrain, Xtest, Ytest):\n",
        "    for clf in self._collection:\n",
        "      clf.train(Xtrain, Ytrain, Xtest, Ytest)\n",
        "\n",
        "  def sort_by_accuracy(self):\n",
        "    self._collection.sort(\n",
        "            key = lambda clf: clf.acc\n",
        "        )\n",
        "    \n",
        "  def get_max(self):\n",
        "    return max(self._collection)\n",
        "\n",
        "  def get_list_accuracy(self):\n",
        "    return {\n",
        "        clf.name: clf.acc for clf in self._collection \n",
        "    }\n",
        "  \n",
        "  def __str__(self):\n",
        "    return ('#'*10 + '\\n').join([str(clf) for clf in self._collection])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztzQ--f5r8l7"
      },
      "source": [
        "def get_train_and_test_samples(df_train: pd.DataFrame, df_test: pd.DataFrame, vectorizer) -> tuple:\n",
        "  vectorize = vectorizer(max_features=1000, ngram_range=(1,5))\n",
        "  Xtrain    = vectorize.fit_transform(df_train['quote']).toarray()\n",
        "  Xtest     = vectorize.fit_transform(df_test['quote']).toarray()\n",
        "\n",
        "  encoder   = LabelEncoder()\n",
        "  Ytrain    = encoder.fit_transform(df_train['score'])\n",
        "  Ytest     = encoder.fit_transform(df_test['score'])\n",
        "  return (Xtrain, Ytrain, Xtest, Ytest)\n",
        "\n",
        "def get_collection_of_RFs(clf_collection: ClassifierCollection):\n",
        "  for number_trees in range(25,300,25):\n",
        "    clf_collection.add_classifier(Classifier(\n",
        "        RandomForestClassifier(n_estimators = number_trees), \n",
        "        \"Random Forest n_estimators = %i\" %(number_trees)))\n",
        "\n",
        "def get_collection_of_Bayes(clf_collection: ClassifierCollection):\n",
        "  clf_collection.add_classifier(Classifier( GaussianNB(), \"GaussianNB\"))\n",
        "\n",
        "def get_collection_of_XGB(clf_collection: ClassifierCollection):\n",
        "  clf_collection.add_classifier(Classifier( xgb.XGBClassifier(),   \"XGB\"))\n",
        "  clf_collection.add_classifier(Classifier( xgb.XGBRFClassifier(), \"XGBRF\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymGG9Ov3paDO"
      },
      "source": [
        "The experiment is carried out with both balanced and unbalanced data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzCoWMYEdFAk"
      },
      "source": [
        "### Balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5DAWOJVdESw"
      },
      "source": [
        "df_train = pd.read_csv(\"%s/train_data_ba.csv\" %data_dir)\n",
        "df_val   = pd.read_csv(\"%s/val_data_ba.csv\" %data_dir)\n",
        "df_train = pd.concat([df_train, df_val])\n",
        "df_test  = pd.read_csv(\"%s/test_data_ba.csv\" %data_dir)\n",
        "\n",
        "Xtrain, Ytrain, Xtest, Ytest = get_train_and_test_samples(df_train, \n",
        "                                                        df_test, \n",
        "                                                        TfidfVectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfe3dzVLdPQk"
      },
      "source": [
        "### UnBalanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZLdrfJmdOkZ"
      },
      "source": [
        "df_train = pd.read_csv(\"%s/train_data_un.csv\" %data_dir)\n",
        "df_val   = pd.read_csv(\"%s/val_data_un.csv\" %data_dir)\n",
        "df_train = pd.concat([df_train, df_val])\n",
        "df_test  = pd.read_csv(\"%s/test_data_un.csv\" %data_dir)\n",
        "\n",
        "Xtrain, Ytrain, Xtest, Ytest = get_train_and_test_samples(df_train, \n",
        "                                                        df_test, \n",
        "                                                        TfidfVectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6D_3ANidRrn"
      },
      "source": [
        "### Experiment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "socG_J6dqdMx"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqH_uxTXSbd7"
      },
      "source": [
        "clf_collection_tf = ClassifierCollection([])\n",
        "get_collection_of_RFs(clf_collection_tf)\n",
        "clf_collection_tf.train(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo6tId_R4riw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d971b2-21ff-4c40-8419-4645ecdf1827"
      },
      "source": [
        "print(clf_collection_tf.get_max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest n_estimators = 50:\n",
            "Accurracy: 45.2351\n",
            "Recall and Precision:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.60      0.57       375\n",
            "           1       0.38      0.47      0.42       262\n",
            "           2       0.14      0.05      0.07       150\n",
            "\n",
            "    accuracy                           0.45       787\n",
            "   macro avg       0.36      0.37      0.35       787\n",
            "weighted avg       0.41      0.45      0.43       787\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTVG0m8qhTo"
      },
      "source": [
        "#### Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrWlNTOGEQJr"
      },
      "source": [
        "clf_collection_tf = ClassifierCollection([])\n",
        "get_collection_of_Bayes(clf_collection_tf)\n",
        "clf_collection_tf.train(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaFgP4oMSpSv",
        "outputId": "490fa5bb-91ed-4c4a-a58b-06b1083693ed"
      },
      "source": [
        "print(clf_collection_tf.get_max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNB:\n",
            "Accurracy: 34.5616\n",
            "Recall and Precision:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.41      0.44       375\n",
            "           1       0.30      0.27      0.28       262\n",
            "           2       0.22      0.33      0.26       150\n",
            "\n",
            "    accuracy                           0.35       787\n",
            "   macro avg       0.33      0.34      0.33       787\n",
            "weighted avg       0.37      0.35      0.35       787\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t336aH-Nqknw"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6Zr_0hXq9g"
      },
      "source": [
        "clf_collection_tf = ClassifierCollection([])\n",
        "get_collection_of_XGB(clf_collection_tf)\n",
        "clf_collection_tf.train(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DkoSM02XvgV",
        "outputId": "c87aca2f-6ea4-45f0-a678-a61a80cf9623"
      },
      "source": [
        "print(clf_collection_tf.get_max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGB:\n",
            "Accurracy: 50.3177\n",
            "Recall and Precision:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.94      0.66       375\n",
            "           1       0.49      0.15      0.23       262\n",
            "           2       0.27      0.02      0.04       150\n",
            "\n",
            "    accuracy                           0.50       787\n",
            "   macro avg       0.42      0.37      0.31       787\n",
            "weighted avg       0.46      0.50      0.40       787\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}